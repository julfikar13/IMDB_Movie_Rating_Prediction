# -*- coding: utf-8 -*-
"""IMDB Movie Rating Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p5a7wlmNlP2vslt-kIL6RZb4SjH2k4eb
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LassoCV
import xgboost as xgb
from sklearn.metrics import mean_squared_error, accuracy_score, r2_score, mean_absolute_error
from sklearn import metrics

# Reading the dataset( Membaca himpunan data)
df=pd.read_csv('drive/My Drive/movie_metadata.csv')
df

pd.set_option('display.max_columns', None)
df.head( )

# the dataset has around 5043 rows and 28 columns( himpunan data memiliki sekitar 5043 baris dan 28 kolom)
df.shape

# Checking the informasion on the dataset(Memeriksa informasion pada himpunan data)
df.info()

# there are null values present in this dataset which have to be imputed
df.isnull().sum

# Displaying all the column names present in the dataframe.
df.columns

# We have 4815 colour movies and 209 Black and white movies.
df['color'].value_counts()

#using the describe function to check the min, max values as well as mean and standard deviation
df.describe()

#displays the total number of variables present in the data frames columns
df.nunique()

# A lot of movies in this dataset are in english
df['language'].value_counts()

#displaying all the movie names
df['movie_title']

#printing the name of Hindi movies present in the dataset
df.movie_title[df.language=='Mandarin']

#saving the Hindi movies into a separate dataframe for futher analysis
bw=df[df.language=='Mandarin']

# storing movies with IMDb score equal to 8 or above 8
scores=bw.imdb_score[bw.imdb_score>=7]

# data frame of all mandarin movies with high IMDb score
bw

# storing movie_titles with imdb scores above 8 or equal to 8
name=bw.movie_title[bw.imdb_score>=7]

#storing movies genre with imdb score above or equal to 8
genre=bw.genres[bw.imdb_score>=7]

#creating a dataframe with all values concatenated into one dataframe
bollywoodmovieratings=pd.concat([name,genre,scores],axis=1)

#final concatenated dataframe of mandarin movies and their genres and imdb_scores
bollywoodmovieratings

"""Data visualization"""

sns.pairplot(data=df)

#pie plot for top 10 Imdb_scores
#around 11.74 percent of the data has a imdb_score which is 6.7
f,ax=plt.subplots(figsize=(10,20))
ax1=plt.subplot(211)
f.suptitle("Imdb score distribution")
explode=(0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05)
df['imdb_score'].value_counts(ascending=False).head(10).plot(kind='pie',autopct="%0.2f%%",explode=explode,ax=ax1)

#visualizing the count of languages in the dataset
sns.set_style("darkgrid")
ls=df['language'].value_counts().head(15).sort_values(ascending=False)
plt.figure(figsize=(15,8))
temp =sns.barplot(ls.index, ls.values,alpha=0.8)
plt.ylabel('COUNT', fontsize=14)
plt.xlabel('Type of Language', fontsize=28)
temp.set_xticklabels(rotation=90,labels=ls.index,fontsize=15)
plt.show()

# Distribution plot for all prices.
f,ax=plt.subplots(figsize=(30,10))
ax3=plt.subplot(224)
sns.distplot(df['imdb_score'],ax=ax3)

# Visualizing the Directors names present in the dataset.
sns.set_style("darkgrid")
ls=df['director_name'].value_counts().head(20).sort_values(ascending=False)
plt.figure(figsize=(15,8))
temp =sns.barplot(ls.index, ls.values, alpha=0.8)
plt.ylabel('COUNT', fontsize=14)
plt.xlabel('name of Director', fontsize=28)
temp.set_xticklabels(rotation=90,labels=ls.index,fontsize=15)
plt.show()

#visualizing the barplot of countries and the imdb scores
plt.figure(figsize=(24,6))
sns.barplot(x='country',y='imdb_score',data=df);
plt.xticks(rotation=90)

# This visualization shows the type of content having higher imdbscore and shows us the type of movie color present in data
plt.figure(figsize=(20,6))
sns.barplot(x='content_rating',y='imdb_score',hue='color',data=df);
plt.xticks(rotation=90)

# This visualization shows the type of content rating on X-axis having aspect ratio on Y-axis and hue with type of movie color.
plt.figure(figsize=(20,6))
sns.barplot(x='content_rating',y='aspect_ratio',hue='color',data=df);
plt.xticks(rotation=90)

# This visualization shows the aspect ratio and its imdb score with hue as the color column.
plt.figure(figsize=(20, 6))
sns.barplot(x='aspect_ratio',y='imdb_score',hue='color',data=df);
plt.xticks(rotation=90)

df=df.dropna()

df.isnull().sum()

df.columns

df=df.drop(columns=['movie_imdb_link','color','movie_title','facenumber_in_poster', 'plot_keywords',
                    'actor_3_name','movie_imdb_link','aspect_ratio','language'])

df

# The number of columns have now been reduced to 28
df.shape

cat_cols=['content_rating','director_name','genres','actor_1_name','actor_2_name','country']
le=LabelEncoder()
for i in cat_cols:
    df[i]=le.fit_transform(df[i])
df.dtypes
## We have label encoded the categorical columns in the dataset and transformed them to numeric values.

"""Label Encoding Categorical data

Distribution Plot
"""

rows=4
cols=5
fig, ax=plt.subplots(nrows=rows,ncols=cols,figsize=(20,20))
col=df.columns
index=0
for i in range(rows):
    for j in range(cols): 
        sns.distplot(df[col[index]],ax=ax[i][j])
        index=index+1
        
plt.tight_layout()
# The distribution plot shows us the overall distribution of the data.

"""Log Transformation"""

# Displaying all column names,copypaste this in the next cell.
df.columns

# Selecting all features which are skewed and storing them in the skewed_features
skewed_features=['director_name', 'num_critic_for_reviews', 'duration',
       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',
       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',
       'num_voted_users', 'cast_total_facebook_likes', 'num_user_for_reviews',
       'country', 'content_rating', 'budget', 'title_year',
       'actor_2_facebook_likes', 'imdb_score', 'movie_facebook_likes']

# Applying log transformation on the skewed features    
for i in skewed_features:
    df[i]=np.log(df[i]+1)

# Checking the changes in the distribution of data after applying log transformation.
rows=4
cols=5
fig, ax=plt.subplots(nrows=rows,ncols=cols,figsize=(20,20))
col=df.columns
index=0
for i in range(rows):
    for j in range(cols):
        sns.distplot(df[col[index]],ax=ax[i][j])
        index=index+1
        
plt.show()

"""Splitting Dataset"""

# splitting data into dependent and independent variables
X=df.drop(labels=['imdb_score'],axis=1)
Y=df['imdb_score']
X.head()

# target column
Y.head()

# Train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=40)
print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)
# Splitting data set into training and testing.

"""Machine Learning

Linear Regression
"""

lm=LinearRegression()   
lm = lm.fit(X_train,Y_train)
#Traindata Predictions
train_pred = lm.predict(X_train)
#testdata predictions
test_pred = lm.predict(X_test) 
RMSE_test = np.sqrt(mean_squared_error(Y_test, test_pred))
RMSE_train= np.sqrt(mean_squared_error(Y_train,train_pred))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:',lm.score(X_train, Y_train))
print('RSquared value on test:',lm.score(X_test, Y_test))

errors = abs(test_pred - Y_test)
# Calculating errors for using error values in mean absolute percentage error

# Calculate mean absolute percentage error (MAPE)
mape = 100 * (errors / Y_test)
# Calculate and display accuracy
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

"""Decision Tree Regression"""

DT=DecisionTreeRegressor(max_depth=9)
DT.fit(X_train,Y_train)
#predicting train
train_preds=DT.predict(X_train)
#predicting on test
test_preds=DT.predict(X_test)
RMSE_train=(np.sqrt(metrics.mean_squared_error(Y_train,train_preds)))
RMSE_test=(np.sqrt(metrics.mean_squared_error(Y_test,test_preds)))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:',DT.score(X_train, Y_train))
print('RSquared value on test:',DT.score(X_test, Y_test))

errors = abs(test_preds - Y_test)
# Calculating errors for using error values in mean absolute percentage error

# Calculate mean absolute percentage error (MAPE)
mape = 100 * (errors / Y_test)
# Calculate and display accuracy
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

"""Random Forest Regression"""

RF=RandomForestRegressor().fit(X_train,Y_train)

#predicting train
train_preds1=RF.predict(X_train)
#predicting on test
test_preds1=RF.predict(X_test)

RMSE_train=(np.sqrt(metrics.mean_squared_error(Y_train,train_preds1)))
RMSE_test=(np.sqrt(metrics.mean_squared_error(Y_test,test_preds1)))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:',RF.score(X_train, Y_train))
print('RSquared value on test:',RF.score(X_test, Y_test))

errors = abs(test_preds1 - Y_test)
# Calculating errors for using error values in mean absolute percentage error

# Calculate mean absolute percentage error (MAPE)
mape = 100 * (errors / Y_test)
# Calculate and display accuracy
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

"""Lasso Regression"""

lasso = LassoCV(cv=10).fit(X_train, Y_train)

#predicting train
train_preds3=lasso.predict(X_train)
#predicting on test
test_preds3=lasso.predict(X_test)

RMSE_train=(np.sqrt(metrics.mean_squared_error(Y_train,train_preds3)))
RMSE_test=(np.sqrt(metrics.mean_squared_error(Y_test,test_preds3)))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:',lasso.score(X_train, Y_train))
print('RSquared value on test:',lasso.score(X_test, Y_test))

errors = abs(test_preds1 - Y_test)
# Calculating errors for using error values in mean absolute percentage error

# Calculate mean absolute percentage error (MAPE)
mape = 100 * (errors / Y_test)
# Calculate and display accuracy
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')